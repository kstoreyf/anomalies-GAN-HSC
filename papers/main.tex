\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
      \PassOptionsToPackage{compress,sort}{natbib}
% before loading neurips_2020

% ready for submission \KSF: THIS ONE!
\usepackage{neurips_2020} 

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
%      \usepackage[nonatbib]{neurips_2020}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
 
% user packages
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{xcolor,listings}
\graphicspath{ {./images/} }

% USER-DEFINED COMMANDS
\DeclareMathOperator*{\maxi}{max}
\DeclareMathOperator*{\mini}{min}
\title{Anomaly Detection in Astronomical Images with Generative Adversarial Networks}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
    {Kate Storey-Fisher} \\
    Center for Cosmology and Particle Physics, Department of Physics \\
    New York University, NY 10003 \\
    \texttt{k.sf@nyu.edu} \\
    \And
    Marc Huertas-Company \\
    LERMA, Observatoire de Paris, PSL Research University, 
    CNRS, Sorbonne Universit\'es, \\
    UPMC Univ. Paris 06,F-75014 Paris, France \\
    \texttt{marc.huertas.company@gmail.com} \\
    \AND
    Nesar Ramachandra \\
    Argonne National Laboratory \\
    \And
    Francois Lanusse \\
    AIM, CEA, CNRS, Universit\'e Paris-Saclay, Universit\'e Paris Diderot \\
    \AND
    Alexie Leauthaud \\
    UC Santa Cruz \\
    \And
    Song Huang \\
    UC Santa Cruz \\
    \And
    Yifei Luo \\
    UC Santa Cruz \\
}

\begin{document}

\maketitle

\begin{abstract}
    We present an anomaly detection method using Wasserstein generative adversarial networks (WGANs) on optical galaxy images from the wide-field survey conducted with the Hyper Suprime-Cam (HSC) on the Subaru Telescope in Hawai'i.\footnote{\url{https://hsc.mtk.nao.ac.jp/ssp/}}
    The WGAN is trained on the entire sample, and learns to generate realistic HSC-like images that follow the distribution of the training data.
    We identify images which are less well-represented in the generator's latent space, and which the discriminator flags as less realistic; these are thus anomalous with respect to the rest of the data.
    We propose a new approach to characterize these anomalies based on a convolutional autoencoder (CAE) to reduce the dimensionality of the residual differences between the real and WGAN-reconstructed images.
    We construct a subsample of $\sim$9,000 highly anomalous images from our nearly million object sample, and further identify interesting anomalies within these; these include galaxy mergers, tidal features, and extreme star-forming galaxies.
    The proposed approach could boost unsupervised discovery in the era of big data astrophysics.
\end{abstract}


\section{Introduction}

Many discoveries in astronomy have been made by identifying unexpected outliers in collected data (e.g. \citealt{Cardamone2009}, \citealt{Massey2019}). 
As data sets increase in size, automated methods for detecting these outliers are critical; for example, the upcoming Rubin Observatory will observe 40 billion objects \citep{Ivezic2018}.
This and other large surveys present opportunities for novel discoveries in their massive data sets.

Unsupervised machine learning lends itself to this problem, as it allows for outlier identification without expert labelling of training data or introducing biases based on expected outliers.
These methods have already proven useful in astronomy (e.g.~\citealp{Baron2017,Solarz2017,Giles2019,Ishida2019,Pruzhinskaya2019}).
Generative Adversarial Networks (GANs) have a natural application to identifying outliers, as they are able to model complex distributions of high-dimensional data.
The generator will be able to better model images that are more common in the training set, and will perform worse on images that are more anomalous relative to the rest of the data.
The discriminator learns to distinguish between real and generated images, and will identify the poorly generated images which tend to be more anomalous.
GANs were first applied to anomaly detection by \cite{Schlegl2017}, in the context of medical imaging, and have since been used to detect outliers in time-series data \citep{Li2018}.
Recently \cite{Margalef-Bentabol2020} used a GAN to detect merging galaxies and compare galaxy simulations against observations. 

In this work, we train a Wasserstein GAN to identify anomalous objects in a subsample of images of the deep sky.
We then characterize the anomalous images with a new convolutional autoencoder-based approach, and identify a set of scientifically interesting anomalies.

\section{Data}
\label{data}

We use data from the Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP).
The wide-field optical survey is imaged with the Subaru Telescope in 5 filters and has been ongoing since March 2014.
The second public data release (PDR2, \citealt{Aihara2014}) contains over 430 million primary objects in the wide field covering 1114 deg$^2$.

We start from a catalog of detected objects and choose a magnitude slice for our analysis ($20.0<i<20.5$) to have a more consistent sample in object size. 
We generate cutouts of $96 \times 96$ pixels ($\sim15\times 15$ arcsec) around each object; this captures the entirety of most objects while still being a reasonable size for training the network.
We use the $gri$-bands to get 3-color images.
This results in a sample of 942,782 objects, consisting of $\sim$70\% extended objects and $\sim$30\% compact objects.

We first preprocess the images to avoid issues due to the raw data range spanning multiple orders of magnitude.
We convert the flux values to RGB values using the method of \citealt{Lupton2004}, producing values from 0 to 255 for each pixel in each band, and then normalize these values individually to between 0 and 1.


\section{Model \& Training}
\label{headings}

\subsection{WGAN Architecture and Training}

We construct a standard Wasserstein generative adversarial network with Gradient Penalty based on the implementation by \cite{Gulrajani2017}.

We construct our generator to have a depth of 4 with a latent space of dimension 128, and a sigmoid activation function.
The discriminator also has a depth of 4.
We train the WGAN in batches of 32 images, with 5 discriminator updates per generator update.
We finalize the model at around 10,000 training iterations, after which the generator and discriminator losses stabilize and no longer improve.

\subsection{Anomaly Scores}

We apply the trained generator to generate its best reconstruction of each image in the sample.
To do this, we assign each  reconstruction a generator score and a discriminator score.
The generator score $s_\mathrm{gen}$ is the mean square error (MSE) of the pixel-wise difference between the two images, summed over all bands.
The discriminator also provides a way of measuring how anomalous an image is, as more anomalous images will have larger Wasserstein distances.
To capture this, we use 6x6 representations of the input images extracted from the penultimate layer of the discriminator.
The MSE between this representation for the real and generated image is the discriminator score, $s_\mathrm{disc}$.
The total anomaly score $s_\mathrm{anom}$ is a weighted average of these controlled by a hyperparameter $\lambda$,
\begin{equation}
s_\mathrm{anom} = (1-\lambda) \cdot s_\mathrm{gen} + \lambda \cdot s_\mathrm{disc}.
\end{equation}

\begin{figure}[ht!]
\begin{subfigure}{.325\textwidth}
  \centering
  % include first image
  \includegraphics[width=1\linewidth]{recons_n3n1sig_3}  
  \caption{}
  \label{fig:recon_neg}
\end{subfigure}
\hfill
\begin{subfigure}{.325\textwidth}
  \centering
  % include second image
  \includegraphics[width=1\linewidth]{recons_24sig_3}  
  \caption{}
  \label{fig:recon_3sig}
\end{subfigure}
\hfill
\begin{subfigure}{.325\textwidth}
  \centering
  % include fourth image
  \includegraphics[width=1\linewidth]{recons_59sig_3.png}
  \caption{}
  \label{fig:recon_5sig}
\end{subfigure}
\caption{The results of WGAN image reconstruction. The top row of each panel shows the original image, the second row shows the best WGAN reconstruction, and the bottom row shows the residual between the two. The assigned anomaly score is shown at the top of each column. The images in each panel are random samples of images in the following ranges of anomaly score: (a) significantly below the mean, (b) around $3\sigma$ above the mean, (c) greater than $5\sigma$ above the mean. It is clear that higher anomaly scores are indicative of poorer WGAN reconstructions and hence larger residuals.}
\label{fig:recon}
\end{figure}

The generator attempts to generate a reconstruction with the minimal anomaly score. 
To speed up this process, we propose an improvement as compared to~\cite{Schlegl2017}: we first train an encoder for the whole training sample.
This convolutional network makes a first approximation of the 128-dimensional latent-space vector of the generator.
We then perform a basic optimization for each image individually to reach a lower anomaly score, optimizing for 10 iterations.
We note that the score converges before 10 iterations for most images.
The score after this process for each image is assigned as its final anomaly score.
Higher anomaly scores indicate more anomalous objects, while lower scores indicate objects that are more well-modeled by the WGAN; note that the scores are entirely relative and are meaningful only with respect to the rest of the sample.

The result of this process is shown in Figure \ref{fig:recon}.
We can see that the WGAN is able to generate realistic images; for compact objects with standard colors, it constructs images nearly identical to the original, and assigns the objects low anomaly scores (Figure \ref{fig:recon_neg}).
The model is more challenged to generate objects with rare features or colors, as in the images with scores around $3\sigma$ above the mean shown in Figure \ref{fig:recon_3sig}.
Finally, objects with pipeline errors, such as complete saturation in one of the color bands, have extremely high anomaly scores, as the WGAN struggles to reconstruct them (Figure \ref{fig:recon_5sig}).

We identify 9,648 objects with scores greater than 3$\sigma$ above the mean, just over 1\% of the sample; we take these as our ''anomalies'' and perform further classification on this sample.


\section{Characterization of Anomalies}
\label{charac}

\subsection{Dimensionality Reduction with a Convolutional Autoencoder}

A general problem with anomaly detection is to distinguish potentially interesting objects from trivial data issues.  
We propose here a new approach based on Convolutional Autoencoders (CAEs) to postprocess and explore identified anomalies. 
We expect the residual images, the absolute difference between the real and reconstructed images, to contain information about why the WGAN marked an object as anomalous.
However, the pixel space is very high-dimensional, and contains excess information.
To reduce the dimensionality of the data and isolate the relevant information, we trained a CAE to map the pixels to a 32-dimensional vector.
The CAE has 4 encoding and 4 decoding layers, and uses a standard MSE loss between the true and reconstructed image.

We visualize these autoencoded residual images with a Uniform Manifold Approximation and Projection (UMAP, \citealt{McInnes2018}), which maps the objects into a 2D representation.
We first embed a 100,000 object subsample of our data set (Figure \ref{fig:umap100k}); the objects are colored by anomaly score.
This shows a clear gradient, with the high-scoring objects clustered at one side of the UMAP, confirming that the CAE is capturing information relevant to the anomalous-ness of the image.

We next perform a new UMAP embedding on only the 3$\sigma$ anomalies, as these are the ones we seek to further characterize; this is shown in Figure \ref{fig:umap3sig}.
Note that the particular mapping coordinates are not relevant, only the position of the objects within each embedding.
This mapping displays structure corresponding to anomaly score, with high-scoring objects clustering around the edges.
As these are all high-scoring objects, we expect that the UMAP on the autoencoded residuals will provide a natural method for sorting the anomalies; we explore this in the following section.

\begin{figure}[t!]
\begin{subfigure}{.495\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{umap_100k_resids_auto}  
  \caption{}
  \label{fig:umap100k}
\end{subfigure}
\hfill
\vspace{0cm}
\begin{subfigure}{.495\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{umap_3sig_resids_auto_highlight}  
  \caption{}
  \label{fig:umap3sig}
\end{subfigure}
\begin{subfigure}{.32\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{cluster_bluesf}  
  \caption{}
  \label{fig:bluesf}
\end{subfigure}
\hfill
\begin{subfigure}{.32\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{cluster_extendedpurple}  
  \caption{}
  \label{fig:extendedpurple}
\end{subfigure}
\hfill
\begin{subfigure}{.32\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{cluster_mergers}  
  \caption{}
  \label{fig:mergers}
\end{subfigure}
\vspace{0cm}
\caption{UMAP embeddings on the autoencoded residuals between WGAN-reconstructed and real images, for (a) a random 100,000 object subsample and (b) objects with anomaly scores >3$\sigma$ above the mean. Regions of the UMAP are similar in the features that make them anomalous; we show interesting objects found clustered near each other in UMAP space. Panel (c) shows blue star-forming regions (dark blue stars in (b)), panel (d) shows extended galaxies with active regions (light blue diamonds in (b)), and panel  (e) shows galaxy mergers (green triangles in (b)).}
\label{fig:umap}
\end{figure}

\subsection{Identified Anomalies}

We utilized our WGAN-based anomaly score and our autoencoded residual image UMAP to further explore the objects in our data set.
We built a custom visualization tool to interactively explore the UMAP space.
We investigated different regions of the 3$\sigma$ UMAP and found that similar types of objects were found nearby in this space.
Interesting anomalous objects from three of these regions are shown in the lower panels of Figure \ref{fig:umap}.

Within one region of this mapping, we identified several extremely blue, apparently highly star-forming sources; these are shown in Figure \ref{fig:bluesf}.
Another region featured many extended galaxies with purple regions that may indicate star-formation activity as well (Figure \ref{fig:extendedpurple}).
We also highlight a region with multiple galaxy merger events, or at least overlapping galaxies, as shown in Figure \ref{fig:mergers}.
The proximity of these interesting anomalies in the space of our UMAP indicates that our anomaly detection and characterization method is allowing us to efficiently identify a wide range of objects with high scientific potential.

In order to confirm the scientific interest of these identified anomalies, we chose several seemingly interesting high-anomaly-scoring objects and conducted follow-up spectroscopic observations with the Keck telescope. 
One of these was a blue compact source overlapping a diffuse galaxy.
The analysis is currently in progress, but the spectrum shows that it is an extremely star-forming, metal-poor source that may be a rare Extremely Metal-Poor Galaxy (e.g. \citep{Kojima2019}).
It also has asymmetrical emission features, potentially indicating gaseous outflows and solidifying the fact that our approach detected a scientifically interesting object.

The UMAP of autoencoded residuals combined with the anomaly score also proves very useful for separating pipeline errors from potentially interesting anomalies.
Nearby regions in UMAP space tend to suffer from similar errors, such as saturation in a particular color band or streaks across the image.
This method could be employed to robustly filter out bad images in extremely large samples.

\section{Conclusions}

In this work, we have shown that generative adversarial networks are a promising approach for anomaly detection in astronomical imaging.
We applied our method to $\sim$940,000 images of galaxies from the Hyper Suprime-Cam, and proposed a novel CAE-based approach on the WGAN results to further characterize the anomalies.
We have identified and catalogued a set of interesting anomalies, and performed follow-up observations on several of these.
We plan to publicly release a catalog of our full data set with our WGAN-assigned anomaly scores, together with our custom visualization tool, which we hope will trigger new discoveries. 
Our WGAN + CAE + visualization method provides an approach to anomaly detection that is scalable, reproducible, and removes spontaneity from the discovery process, making it ideal for extracting novel science from the increasingly large surveys of the coming decade.

\section*{Broader Impact}

We hope the present work will help astronomers to make new discoveries in the era of big-data astronomy. 
The work uses public data of the deep sky acquired using a ground-based facility. 
We believe this work does not entail any negative consequences or ethical issues.

\begin{ack}
We gratefully acknowledge the Kavli Summer Program in Astrophysics for seeding this project; the initial work was completed at the 2019 program at the University of California, Santa Cruz.
This work was funded by the Kavli Foundation, the National Science Foundation, and UC Santa Cruz.
KSF thanks Dezso Ribli, Lorenzo Zanisi, Itamar Reis, Xavier Prochaska, Kevin Bundy, Jenny Greene, and Erin Kado-Fong for helpful discussions.
KSF also thanks the Astrodata Group at the Flatiron Center for Computational Astrophysics for useful feedback.
\end{ack}

\bibliographystyle{mnras}
\bibliography{Anomalies-HSC}

\end{document}
